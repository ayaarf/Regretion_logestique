{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89daf7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and scaler trained and saved as Amount_model.pkl and scalerAmount.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_2192\\3858086345.py:27: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query2, conn)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import pickle\n",
    "import pyodbc\n",
    "\n",
    "# Database connection\n",
    "conn = pyodbc.connect('DRIVER={SQL Server};'\n",
    "                      'SERVER=DESKTOP-7QR5TL6;'\n",
    "                      'DATABASE=DWH_SAP;'\n",
    "                      'Trusted_Connection=yes')\n",
    "\n",
    "query2 = \"\"\"\n",
    "SELECT\n",
    "    d.Amount, VATRate, SupplierPrice,\n",
    "    r.*\n",
    "FROM\n",
    "    [DWH_SAP].[dbo].[Dim_Supplier_Invoices] r\n",
    "JOIN\n",
    "    [DWH_SAP].[dbo].[Fact_Etat_Financier] d\n",
    "    ON r.Pk_Supplier_Invoices = d.Fk_supplier_Invoices\n",
    "\"\"\"\n",
    "\n",
    "# Load data\n",
    "df = pd.read_sql(query2, conn)\n",
    "\n",
    "# Preprocessing\n",
    "df.drop(columns=['PaymentDueDate', 'DueDate', 'InvoiceID', 'Pk_Supplier_Invoices', 'Fk_Supplier'], inplace=True)\n",
    "df['log_amount'] = np.log1p(df['Amount'])\n",
    "df['Approved'] = df['Approved'].astype(int)\n",
    "df['PaymentStatus'] = LabelEncoder().fit_transform(df['PaymentStatus'].astype(str))\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['Approved'])\n",
    "y = df['Approved']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "num_cols = ['Amount', 'VATRate', 'SupplierPrice', 'log_amount']\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test_scaled[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)  # Fit on scaled data\n",
    "\n",
    "# Save the model and scaler\n",
    "with open('Amount_model1.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "with open('scalerAmount.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "\n",
    "print(\"Model and scaler trained and saved as Amount_model.pkl and scalerAmount.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb347baa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
